{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises: Day 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises: Level 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What is the most frequent word in the following paragraph?\n",
    "paragraph = 'I love teaching. If you do not love teaching what else can you love. I love Python if you do not love something which can give you all the capabilities to develop an application what else can you love."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent word is: love\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "paragraph = '''I love teaching. If you do not love teaching what else can you love.\n",
    "I love Python if you do not love something which can give you all the capabilities\n",
    "to develop an application what else can you love.'''\n",
    "\n",
    "### Removing punctuations and changing the paragraph to lowercase\n",
    "processed_paragraph = re.sub(r'[^\\w\\s]', '', paragraph.lower())\n",
    "### Finding all the words in the paragraph\n",
    "words = re.findall(r'\\b\\w+\\b', processed_paragraph)\n",
    "\n",
    "word_freq = {}\n",
    "for word in words:\n",
    "    word_freq[word] = word_freq.get(word, 0) + 1\n",
    "\n",
    "most_freq_word = max(word_freq, key=word_freq.get)\n",
    "print(f'The most frequent word is: {most_freq_word}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. The position of some particles on the horizontal x-axis are -12, -4, -3 and -1 in the negative direction, 0 at origin, 4 and 8 in the positive direction. Extract these numbers from this whole text and find the distance between the two furthest particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between the furthest two particles is: 20\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text ='''The position of some particles on the horizontal x-axis are -12, -4, -3 and -1 in the negative direction, 0 at origin, 4 and 8 in the positive direction.'''\n",
    "\n",
    "nums = re.findall(r'-?\\d+', text)\n",
    "nums = [int(num) for num in nums]\n",
    "sorted_points = sorted(nums)\n",
    "distance = sorted_points[-1] - sorted_points[0]\n",
    "print(f'The distance between the furthest two particles is: {distance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises: Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 1. Write a pattern which identifies if a string is a valid python variable\n",
    "\n",
    "import re\n",
    "\n",
    "def is_valid_variable(variable):\n",
    "    pattern = r'^[a-zA-Z_][a-zA-Z0-9_]*$'\n",
    "    return re.match(pattern, variable) is not None\n",
    "\n",
    "print(is_valid_variable('first_name'))   \n",
    "print(is_valid_variable('first-name'))  \n",
    "print(is_valid_variable('1first_name'))  \n",
    "print(is_valid_variable('firstname'))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises: Level 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Clean the following text. After cleaning, count three most frequent words in the string.\n",
    "sentence = '''%I $am@% a %tea@cher%, &and& I lo%#ve %tea@ching%;. There $is nothing; &as& mo@re rewarding as educa@ting &and& @emp%o@wering peo@ple. ;I found tea@ching m%o@re interesting tha@n any other %jo@bs. %Do@es thi%s mo@tivate yo@u to be a tea@cher!?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cleaned text: i am a teacher and i love teaching there is nothing as more rewarding as educating and empowering people i found teaching more interesting than any other jobs does this motivate you to be a teacher\n",
      "The 3 most frequent words are:\n",
      "i: 3\n",
      "a: 2\n",
      "teacher: 2\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_txt = re.sub(r'[^a-zA-Z\\s]', '', text.lower())\n",
    "    cleaned_txt = re.sub(r'\\s+', ' ', cleaned_txt)\n",
    "    return cleaned_txt.strip()\n",
    "\n",
    "def most_freq_words(text, count=3):\n",
    "    words = text.split()\n",
    "    word_counts = Counter(words)\n",
    "    return word_counts.most_common(count)\n",
    "\n",
    "sentence = '''%I $am@% a %tea@cher%, &and& I lo%#ve %tea@ching%;. There $is nothing; &as& mo@re rewarding as educa@ting &and& @emp%o@wering peo@ple. ;I found tea@ching m%o@re interesting tha@n any other %jo@bs. %Do@es thi%s mo@tivate yo@u to be a tea@cher!?'''\n",
    "\n",
    "cleaned_txt = clean_text(sentence)\n",
    "print(f'The cleaned text: {cleaned_txt}')\n",
    "\n",
    "most_freq = most_freq_words(cleaned_text)\n",
    "print('The 3 most frequent words are:')\n",
    "for count, word in most_freq:\n",
    "    print(f'{count}: {word}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
